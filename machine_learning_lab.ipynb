{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xtzXAHVBwNFR",
        "outputId": "bfa992d1-a800-46ea-d0ab-5248f24f9098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from idx2numpy) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from idx2numpy) (1.17.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=83d55391c537d69a72f8bee07eaadfef46715e37c9c9b2c528de4a1bcba28526\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/e5/e7/70fc742b3645ddf9d392f766feccbcc95cb3a3c806f8588af0\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install idx2numpy\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI7lmO8VwNFU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import idx2numpy\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boVnt9bFwNFV",
        "outputId": "a9eba790-72b8-4ea0-8e1b-d64fea908131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZlf2v6LwNFV"
      },
      "source": [
        "# **Question 1**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJRxl_SowNFW",
        "outputId": "99562985-9875-4426-c0ef-f10714c3ef69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images shape (60000, 28, 28)\n",
            "Training labels shape (60000,)\n",
            "Test images shape (10000, 28, 28)\n",
            "Test labels shape (10000,)\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/data.zip\"\n",
        "\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "train_images_path = \"train/train-images-idx3-ubyte\"\n",
        "train_labels_path = \"train/train-labels-idx1-ubyte\"\n",
        "test_images_path = \"test/test-images-idx3-ubyte\"\n",
        "test_labels_path = \"test/test-labels-idx1-ubyte\"\n",
        "\n",
        "train_images = idx2numpy.convert_from_file(train_images_path)\n",
        "train_labels = idx2numpy.convert_from_file(train_labels_path)\n",
        "test_images = idx2numpy.convert_from_file(test_images_path)\n",
        "test_labels = idx2numpy.convert_from_file(test_labels_path)\n",
        "\n",
        "print(f'Training images shape {train_images.shape}')\n",
        "print(f'Training labels shape {train_labels.shape}')\n",
        "print(f'Test images shape {test_images.shape}')\n",
        "print(f'Test labels shape {test_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJH4Dxd9wNFW",
        "outputId": "3b6de6ae-c57b-4815-aa66-d8be5779586e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images mean = 0.1306604762738429\n",
            "Train images std = 0.30810780385646264\n",
            "Test images mean = 0.13251460584233693\n",
            "Test images std = 0.3104802479305351\n"
          ]
        }
      ],
      "source": [
        "mean_train = np.mean(train_images)/255\n",
        "std_train = np.std(train_images)/255\n",
        "\n",
        "mean_test = np.mean(test_images)/255\n",
        "std_test = np.std(test_images)/255\n",
        "\n",
        "print(f'Train images mean = {mean_train}')\n",
        "print(f'Train images std = {std_train}')\n",
        "print(f'Test images mean = {mean_test}')\n",
        "print(f'Test images std = {std_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qlIPLHDwNFX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean_train, std = std_train)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWtL_9okwNFX"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aadPpgrwNFX",
        "outputId": "f4d83c10-cc60-4a79-a4d8-0e2084222ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images length = 48000\n",
            "Validation images length = 12000\n",
            "Test images length = 10000\n"
          ]
        }
      ],
      "source": [
        "full_train_dataset = CustomDataset(train_images, train_labels, transform)\n",
        "test_dataset = CustomDataset(test_images, test_labels, transform)\n",
        "\n",
        "train_dataset, val_dataset = train_test_split(full_train_dataset, test_size = 0.2, random_state = 42)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_dataloader = DataLoader(test_images, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f'Training images length = {len(train_dataset)}')\n",
        "print(f'Validation images length = {len(val_dataset)}')\n",
        "print(f'Test images length = {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK8sbRr5wNFY",
        "outputId": "9e4b42be-7429-4c6f-9785-a5ffb3f2cd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "one_hot_labels = F.one_hot(torch.tensor(test_labels, dtype = torch.long), num_classes=10)\n",
        "print(one_hot_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7oUAlvFwNFY"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcX3Jo3swNFZ",
        "outputId": "423542a4-c556-4eac-bff1-4e50c1bf1e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9193\n",
            "Precision: 0.91906972268138\n",
            "Recall: 0.9193\n",
            "F1 Score: 0.9190867474376774\n"
          ]
        }
      ],
      "source": [
        "train_images = np.array([item[0].numpy().flatten() for item in train_dataset])\n",
        "train_labels = np.array([item[1] for item in train_dataset])\n",
        "\n",
        "test_images = np.array([item[0].numpy().flatten() for item in test_dataset])\n",
        "test_labels = np.array([item[1] for item in test_dataset])\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(train_images, train_labels)\n",
        "test_pred = model.predict(test_images)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_pred)\n",
        "precision = precision_score(test_labels, test_pred, average='weighted')\n",
        "recall = recall_score(test_labels, test_pred, average='weighted')\n",
        "f1 = f1_score(test_labels, test_pred, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2S11bMNwNFZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization parameter\n",
        "    'penalty': ['l2'],  # Regularization type\n",
        "    'solver': ['saga'],  # Solver for optimization\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(train_images, train_labels)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_2d = train_images[:, [0, 1]]  # Select features 0 and 1\n",
        "test_images_2d = test_images[:, [0, 1]]\n",
        "\n",
        "model_2d = LogisticRegression(max_iter=1000)\n",
        "model_2d.fit(train_images_2d, train_labels)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a meshgrid for plotting\n",
        "x_min, x_max = train_images_2d[:, 0].min() - 1, train_images_2d[:, 0].max() + 1\n",
        "y_min, y_max = train_images_2d[:, 1].min() - 1, train_images_2d[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "# Predict probabilities for the meshgrid points\n",
        "Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary and data points\n",
        "plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "plt.scatter(train_images_2d[:, 0], train_images_2d[:, 1], c=train_labels, edgecolors='k')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Decision Boundary')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cSJVcBI9Q-is"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}